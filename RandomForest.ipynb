{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.threshold, self.feature_id, self.node_id = -1, -1, -1\n",
    "        self.labels = np.array([])\n",
    "        self.left, self.right = None, None\n",
    "        self.prune_flag = True\n",
    "    def __repr__(self):\n",
    "        return 'Node %d' % self.node_id\n",
    "        #return 'Node for %d feature' % self.feature_id\n",
    "    def set_all(self, threshold, feature_id, node_id, data):\n",
    "        self.threshold, self.feature_id, self.node_id = threshold, feature_id, node_id\n",
    "        self.labels = [data[i][-1] for i in range(len(data))]\n",
    "    def create_left(self):\n",
    "        self.left = Node()\n",
    "    def create_right(self):\n",
    "        self.right = Node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script pypy3\n",
    "\n",
    "import csv, random, math as m, queue, numpy as np\n",
    "\n",
    "class DecisiveTreeFeatureBagging:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.train, self.valid, self.test = np.array([]), np.array([]), np.array([])\n",
    "        self.features, self.root, self.nodesCnt, self.depth_threshold = 0, 0, 0, 13\n",
    "        self.to_preserve, self.to_remove = 0, 1\n",
    "        self.root = None\n",
    "\n",
    "    def set_dataset(self, train, valid, test):\n",
    "        self.train, self.valid, self.test = train, valid, test\n",
    "        self.features = 11\n",
    "\n",
    "    def get_distro(self, data):\n",
    "        labels = data[:,-1]\n",
    "        return np.divide(np.unique(labels, return_counts=True)[1], float(labels.size))\n",
    "\n",
    "    def compute_entropy(self, data):\n",
    "        distro = self.get_distro(data)\n",
    "        log_distro = np.log2(distro)\n",
    "        return 0 if np.count_nonzero(distro)<=1 else (-1 * distro * log_distro).sum()\n",
    "\n",
    "    def information_gain(self, val, fea_id, entropy, data):\n",
    "        smaller = data[np.where(data[:,fea_id]<=val)]\n",
    "        greater = data[np.where(data[:,fea_id]>val)]\n",
    "        prob_smaller = float(smaller.shape[0]) / (smaller.shape[0] + greater.shape[0])\n",
    "        prob_greater = float(greater.shape[0]) / (smaller.shape[0] + greater.shape[0])\n",
    "        s_entropy = self.compute_entropy(smaller)\n",
    "        g_entropy = self.compute_entropy(greater)\n",
    "        return (entropy - (prob_smaller*s_entropy + prob_greater*g_entropy), smaller, greater)\n",
    "\n",
    "    def feature_choice_feature_bagging(self, data, avail_features):\n",
    "        maxIG = (-1, 0, 0, [], [])\n",
    "        thres, samples = self.features, data.shape[0]\n",
    "        entropy = self.compute_entropy(data)\n",
    "        for fea_id in avail_features:\n",
    "            for split_id in range(samples):\n",
    "                inf_gain = self.information_gain(data[split_id, fea_id], fea_id, entropy, data)\n",
    "                if maxIG[0] < inf_gain[0]:\n",
    "                    maxIG = (inf_gain[0], split_id, fea_id, inf_gain[1], inf_gain[2])\n",
    "        return maxIG[1:]\n",
    "\n",
    "    def set_root_node(self, split_id, fea_id):\n",
    "        self.root = Node()\n",
    "        self.root.set_all(self.train[split_id][fea_id], fea_id, self.nodesCnt, self.train)\n",
    "        self.nodesCnt += 1\n",
    "\n",
    "    def setup_node(self, data, node, split_id, fea_id):\n",
    "        node.set_all(data[split_id][fea_id], fea_id, self.nodesCnt, data)\n",
    "        self.nodesCnt += 1\n",
    "\n",
    "    def get_available_features(self):\n",
    "        formula = m.ceil(m.sqrt(11))\n",
    "        sample_to_choose = int(formula) if formula > 0 else 1\n",
    "        return np.random.choice(11, sample_to_choose, replace=False)\n",
    "    \n",
    "    def create_tree_feature_bagging(self):\n",
    "        avail_features = self.get_available_features()\n",
    "        split_id, fea_id, s, g = self.feature_choice_feature_bagging(self.train, avail_features)\n",
    "        self.set_root_node(split_id, fea_id)\n",
    "        que = queue.Queue()\n",
    "        que.put((self.root, 'l', s, 1))\n",
    "        que.put((self.root, 'r', g, 1))\n",
    "        while not que.empty():\n",
    "            node, side, data, depth = que.get()\n",
    "            if depth > self.depth_threshold or len(data) == 0:\n",
    "                continue\n",
    "            node.create_left() if side == 'l' else node.create_right()\n",
    "            node = node.left if side == 'l' else node.right\n",
    "            avail_features = self.get_available_features()\n",
    "            split_id, fea_id, s, g = self.feature_choice_feature_bagging(data, avail_features)\n",
    "            self.setup_node(data, node, split_id, fea_id)\n",
    "            que.put((node, 'l', s, depth+1))\n",
    "            que.put((node, 'r', g, depth+1))\n",
    "\n",
    "    def calculate_accuracy(self, result, predicted_result):\n",
    "        return np.sum(result == predicted_result) / float(result.size)\n",
    "    \n",
    "    def set_next_node(self, t, val_fea_id):\n",
    "        if t.left is None or t.right is None:\n",
    "            return t.left if t.right is None else t.right\n",
    "        else:\n",
    "            return t.right if val_fea_id > t.threshold else t.left\n",
    "    \n",
    "    def evaluate_one_sample(self, node, sample):\n",
    "        while True:\n",
    "            if node.left is None and node.right is None:\n",
    "                label = np.argmax(np.bincount(node.labels))\n",
    "                return int(sample[-1]), int(label)\n",
    "            else:\n",
    "                node = self.set_next_node(node, sample[node.feature_id])\n",
    "\n",
    "    def evaluate_tree(self, test_data):\n",
    "        predicted_result, result = [], []\n",
    "        for sample in test_data:\n",
    "            t = self.root\n",
    "            sample_label, pred_label = self.evaluate_one_sample(t, sample)\n",
    "            result.append(sample_label)\n",
    "            predicted_result.append(pred_label)\n",
    "        result, predicted_result = np.asarray(result), np.asarray(predicted_result)\n",
    "        accuracy = self.calculate_accuracy(result, predicted_result)\n",
    "        return (\"Accuracy obtained on test data is %f\" % accuracy, accuracy, result, predicted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script pypy3\n",
    "\n",
    "import csv, random, math as m, queue, numpy as np\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.card_forest, self.samples_per_tree = 40, 2200\n",
    "        self.feature_bagging = np.array((self.samples_per_tree, self.card_forest))\n",
    "        self.values, self.train, self.valid, self.test = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "        self.forest = [DecisiveTreeFeatureBagging(file) for _ in range(self.card_forest)]\n",
    "        self.bags = np.empty([self.card_forest, self.samples_per_tree])\n",
    "\n",
    "    def create_dataset(self, train_ratio=5, valid_ratio=1, test_ratio=1):\n",
    "        with open(self.file) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            splitted_lines = [x[0].split(';') for x in csv_reader]\n",
    "            self.columns = [str(el.replace('\"', '')) for el in splitted_lines[0]]\n",
    "            self.features = len(splitted_lines[0]) - 1\n",
    "            self.used_in_tree = [False] * self.features\n",
    "            for line in splitted_lines[1:]:\n",
    "                line = [float(el) for el in line]\n",
    "                self.values = np.asarray(line) if self.values.size == 0 else np.vstack((self.values, np.asarray(line)))\n",
    "        self.extract_datasets(train_ratio, valid_ratio, test_ratio)\n",
    "\n",
    "    def extract_datasets(self, train_ratio, valid_ratio, test_ratio):\n",
    "        n = self.values.shape[0]\n",
    "        all_ratio = train_ratio + test_ratio + valid_ratio\n",
    "        np.random.shuffle(self.values)\n",
    "        self.train = np.asarray(self.values[:int((train_ratio*n)/all_ratio)])\n",
    "        self.valid = np.asarray(self.values[int((train_ratio*n)/all_ratio):int(((train_ratio+valid_ratio)*n)/all_ratio)])\n",
    "        self.test = np.asarray(self.values[int(((train_ratio+valid_ratio)*n)/all_ratio):])\n",
    "\n",
    "    def create_tree(self, tree):\n",
    "        smaller_train = self.train[np.random.choice(list(range(self.train.shape[0])),\n",
    "            self.samples_per_tree, replace=True)]\n",
    "        tree.set_dataset(smaller_train, self.valid, self.test)\n",
    "        tree.create_tree_feature_bagging()\n",
    "\n",
    "    def create_random_forest(self):\n",
    "        for i in range(self.card_forest):\n",
    "            print(\"Creating tree {}\".format(i))\n",
    "            self.create_tree(self.forest[i])\n",
    "            self.evaluate_random_forest(i+1)\n",
    "    \n",
    "    def calculate_accuracy(self, result, predicted_result):\n",
    "        return np.sum(result == predicted_result) / float(result.size)\n",
    "\n",
    "    def evaluate_random_forest(self, nr_trees):\n",
    "        result, pred_result = [], []\n",
    "        labels = self.test[:,-1]\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        pred_good, pred_bad = {k:0 for k in unique}, {k:0 for k in unique}\n",
    "        print('\\n')\n",
    "        print(\"All labels \", dict(zip(unique, counts)))\n",
    "        for sample in self.test:\n",
    "            res_for_sample = []\n",
    "            for j in range(nr_trees):\n",
    "                t = self.forest[j].root\n",
    "                real, pred = self.forest[j].evaluate_one_sample(t, sample)\n",
    "                res_for_sample.append(pred)\n",
    "            majority = np.argmax(np.bincount(np.asarray(res_for_sample)))\n",
    "            result.append(real)\n",
    "            pred_result.append(majority)\n",
    "            if real == majority:\n",
    "                pred_good[real] += 1\n",
    "            else:\n",
    "                pred_bad[real] += 1\n",
    "        print(\"Good predictions \", pred_good)\n",
    "        print(\"Bad predictions \", pred_bad)\n",
    "        result, predicted_result = np.asarray(result), np.asarray(pred_result)\n",
    "        accuracy = self.calculate_accuracy(result, predicted_result)*100\n",
    "        print(\"Accuracy obtained on test data is %f\" % accuracy)\n",
    "        return (\"Accuracy obtained on test data is %f\" % accuracy, accuracy, result, predicted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script pypy3\n",
    "\n",
    "import sys\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_file = \"dataset/winequality-white.csv\"\n",
    "    results_sum, required = 0.0, 0.500000\n",
    "    samples, better_than_required = 10, 0\n",
    "    custom_split = False\n",
    "    \n",
    "    rf = RandomForest(input_file)\n",
    "    rf.create_dataset() if not custom_split else rf.create_dataset(train_ratio, valid_ratio, test_ratio)\n",
    "    rf.create_random_forest()\n",
    "    info, accuracy, res_labels, predicted_labels = rf.evaluate_random_forest(rf.card_forest)\n",
    "    print(info)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
